{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cL_J3IrHTJ-t"
   },
   "source": [
    "### Instruction\n",
    "Before using this file, please make sure that these tasks are completed:\n",
    "- Convert all the images to the target size using `transform_image.py`\n",
    "- Annotate the test set and the train set using `labelImg` module into `pascal` form\n",
    "- Convert the resulting `.xml` file into `.csv` using `xml_to_csv.py`\n",
    "\n",
    "#### Jupyter Notebook on Windows\n",
    "https://github.com/philferriere/cocoapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk_dQTnpRmYP"
   },
   "source": [
    "#### Mounting Project data from Gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "ybTUk3-GQvfG",
    "outputId": "0327e7a3-4c2e-4a5b-8be1-8dc1a4faba80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive not mounted, so nothing to flush and unmount.\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zm-xjF0ZX_dE"
   },
   "source": [
    "#### Setting Tensorflow Object Detection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BHu-Oo3PXdSx",
    "outputId": "2f94f764-cd58-4900-902c-34f6ab0100cf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in c:\\users\\andre\\anaconda3\\lib\\site-packages (0.29.14)\n",
      "[WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research'\n",
      "C:\\Users\\andre\\Documents\\cds_nude_censoring\n",
      "env: PYTHONPATH=/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research:/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/slim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object_detection/protos/*.proto: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.76 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'object_detection/builders/model_builder_test.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install Cython\n",
    "\n",
    "# !git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "%cd /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research\n",
    "\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "%set_env PYTHONPATH=/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research:/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/slim\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "y66gIDc_XWBs",
    "outputId": "397186d9-3119-4e76-e7f0-de449abb9369"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  C:\\Users\\andre\\Documents\\cds_nude_censoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Skip to this step if you are running on Windows Jupyter. make sure cwd is in models/research\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "# os.chdir('../../')\n",
    "print(\"Current working directory: \", os.getcwd()) # Should be /content/gdrive/My Drive/SUTD/cds_nude_censoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6QrHA9gRlc5"
   },
   "source": [
    "#### Generating Tensorflow Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Csbi9HU0YZJd"
   },
   "outputs": [],
   "source": [
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'breast':\n",
    "        return 1\n",
    "    elif row_label == 'breasts':\n",
    "        return 2\n",
    "    elif row_label == 'penis':\n",
    "        return 3\n",
    "    elif row_label == 'vagina':\n",
    "        return 4\n",
    "    elif row_label == 'fucking':\n",
    "        return 5\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def generate_tfrecord(csv_input, output_path, image_dir):\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(image_dir)\n",
    "    examples = pd.read_csv(csv_input)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path = os.path.join(os.getcwd(), output_path)\n",
    "    print('Successfully created the TFRecords: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "UanZohmqbMdD",
    "outputId": "23bfd6c1-0514-4d3d-cbe2-b1dd8eb02860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /content/gdrive/My Drive/SUTD/cds_nude_censoring/test.record\n",
      "CPU times: user 162 ms, sys: 15.1 ms, total: 178 ms\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# generate_tfrecord('data/test_set_labels.csv', 'test.record', 'images/test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BZNz1gFMR7I-",
    "outputId": "549959b9-2ac2-498b-bbcb-d55ad58215f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /content/gdrive/My Drive/SUTD/cds_nude_censoring/train.record\n",
      "CPU times: user 1.7 s, sys: 153 ms, total: 1.86 s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# generate_tfrecord('data/train_set_labels.csv', 'train.record', 'images/train_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4FZiPTIStWY"
   },
   "source": [
    "#### Training the Model\n",
    "Path to model is stored in `pipeline2.config`. Follow instruction in the file to know which paths to change.\n",
    "\n",
    "Model checkpoint will be stored in the mentioned model directory every approximately 3000steps in as a checkpoint file. `model.ckpt-XXXX.data-YYYYY-of-ZZZZZ`\n",
    "\n",
    "The highest number of `XXXX` refers to the latest model model checkpoint. Each models takes approximately 10 minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3hcmnnAPlFFn",
    "outputId": "0d44cb76-9e21-49e7-fc66-555c5ac066f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  C:\\Users\\andre\\Documents\\cds_nude_censoring\\models\\research\\object_detection\n"
     ]
    }
   ],
   "source": [
    "os.chdir('models/research/object_detection')\n",
    "print('Current working directory: ', os.getcwd()) # Should be /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RMWcktPFmsoO",
    "outputId": "6ee559f7-65de-4a01-d53a-48c6fc5d9af8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BdC0FnnilMWO",
    "outputId": "eaa88f85-c64d-4e64-c1e5-ec3b59c7d2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/config_util.py:102: The name tf.io.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1209 16:17:33.288933 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/config_util.py:102: The name tf.io.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W1209 16:17:33.293891 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1209 16:17:33.294065 140132392327040 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1209 16:17:33.294234 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I1209 16:17:33.294367 140132392327040 config_util.py:488] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1209 16:17:33.294464 140132392327040 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I1209 16:17:33.294550 140132392327040 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1209 16:17:33.294641 140132392327040 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
      "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
      "I1209 16:17:33.294737 140132392327040 config_util.py:488] Maybe overwriting load_pretrained: True\n",
      "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
      "I1209 16:17:33.294842 140132392327040 config_util.py:498] Ignoring config override key: load_pretrained\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1209 16:17:33.294960 140132392327040 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "I1209 16:17:33.295109 140132392327040 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f72ad7b3f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I1209 16:17:33.295611 140132392327040 estimator.py:212] Using config: {'_model_dir': 'training2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f72ad7b3f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f72ad74e730>) includes params argument, but params are not passed to Estimator.\n",
      "W1209 16:17:33.295890 140132392327040 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f72ad74e730>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I1209 16:17:33.296859 140132392327040 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I1209 16:17:33.297097 140132392327040 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I1209 16:17:33.297364 140132392327040 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1209 16:17:33.304061 140132392327040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1209 16:17:33.317578 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W1209 16:17:33.317798 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:64: The name tf.io.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W1209 16:17:33.338446 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:64: The name tf.io.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1209 16:17:33.340182 140132392327040 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W1209 16:17:33.346632 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W1209 16:17:33.346807 140132392327040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1209 16:17:33.371233 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
      "\n",
      "W1209 16:17:34.842981 140132392327040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W1209 16:17:43.027994 140132392327040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1209 16:17:43.118857 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1209 16:17:45.611594 140132392327040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W1209 16:17:47.751298 140132392327040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1209 16:17:48.507539 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "W1209 16:17:51.027982 140132392327040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "W1209 16:17:51.712633 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I1209 16:17:51.728979 140132392327040 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1209 16:17:51.753545 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:51.764151 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1209 16:17:51.766747 140132392327040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W1209 16:17:55.518958 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:55.527635 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1209 16:17:55.527990 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:55.545394 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1209 16:17:55.545707 140132392327040 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1209 16:17:56.460135 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W1209 16:17:56.510234 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1209 16:17:56.778929 140132392327040 deprecation.py:506] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W1209 16:17:56.797123 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:56.797484 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1209 16:17:57.148661 140132392327040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:57.151515 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:17:57.172698 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W1209 16:17:57.205434 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W1209 16:17:57.205617 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W1209 16:17:57.209078 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W1209 16:17:57.219761 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W1209 16:17:59.371342 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W1209 16:17:59.372762 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W1209 16:17:59.427533 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W1209 16:17:59.705197 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W1209 16:17:59.706307 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W1209 16:17:59.715068 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W1209 16:17:59.715293 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1209 16:17:59.715492 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1209 16:18:05.475453 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1209 16:18:06.301235 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "W1209 16:18:06.301561 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I1209 16:18:06.301914 140132392327040 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I1209 16:18:06.303418 140132392327040 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I1209 16:18:09.951290 140132392327040 monitored_session.py:240] Graph was finalized.\n",
      "2019-12-09 16:18:09.957309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-12-09 16:18:09.957618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1444cc40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-09 16:18:09.957647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-12-09 16:18:09.959802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2019-12-09 16:18:10.076638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.077895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1444ca80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-09 16:18:10.077941: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2019-12-09 16:18:10.078202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.079062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-09 16:18:10.079430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-09 16:18:10.081358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-09 16:18:10.083419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2019-12-09 16:18:10.083758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2019-12-09 16:18:10.085613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-12-09 16:18:10.086520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-12-09 16:18:10.090238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-09 16:18:10.090399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.091341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.092209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2019-12-09 16:18:10.092270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-09 16:18:10.093877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-09 16:18:10.093907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2019-12-09 16:18:10.093921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2019-12-09 16:18:10.094052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.094973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:18:10.095870: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-12-09 16:18:10.095918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1209 16:19:07.101484 140132392327040 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1209 16:19:07.452812 140132392327040 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training2/model.ckpt.\n",
      "I1209 16:19:17.243839 140132392327040 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training2/model.ckpt.\n",
      "2019-12-09 16:19:25.981403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-09 16:19:27.155208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "INFO:tensorflow:loss = 4.545883, step = 0\n",
      "I1209 16:19:31.231978 140132392327040 basic_session_run_hooks.py:262] loss = 4.545883, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.36616\n",
      "I1209 16:19:54.134503 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 4.36616\n",
      "INFO:tensorflow:loss = 0.1488618, step = 100 (22.904 sec)\n",
      "I1209 16:19:54.135908 140132392327040 basic_session_run_hooks.py:260] loss = 0.1488618, step = 100 (22.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.38166\n",
      "I1209 16:20:12.716129 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.38166\n",
      "INFO:tensorflow:loss = 0.1593453, step = 200 (18.582 sec)\n",
      "I1209 16:20:12.717974 140132392327040 basic_session_run_hooks.py:260] loss = 0.1593453, step = 200 (18.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39217\n",
      "I1209 16:20:31.261520 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39217\n",
      "INFO:tensorflow:loss = 1.3838975, step = 300 (18.545 sec)\n",
      "I1209 16:20:31.262591 140132392327040 basic_session_run_hooks.py:260] loss = 1.3838975, step = 300 (18.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.37744\n",
      "I1209 16:20:49.857721 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.37744\n",
      "INFO:tensorflow:loss = 1.0365434, step = 400 (18.596 sec)\n",
      "I1209 16:20:49.858649 140132392327040 basic_session_run_hooks.py:260] loss = 1.0365434, step = 400 (18.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39257\n",
      "I1209 16:21:08.401785 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39257\n",
      "INFO:tensorflow:loss = 0.27407005, step = 500 (18.544 sec)\n",
      "I1209 16:21:08.403100 140132392327040 basic_session_run_hooks.py:260] loss = 0.27407005, step = 500 (18.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.38717\n",
      "I1209 16:21:26.964325 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.38717\n",
      "INFO:tensorflow:loss = 0.9859308, step = 600 (18.562 sec)\n",
      "I1209 16:21:26.965238 140132392327040 basic_session_run_hooks.py:260] loss = 0.9859308, step = 600 (18.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39354\n",
      "I1209 16:21:45.505076 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39354\n",
      "INFO:tensorflow:loss = 0.89212936, step = 700 (18.541 sec)\n",
      "I1209 16:21:45.506108 140132392327040 basic_session_run_hooks.py:260] loss = 0.89212936, step = 700 (18.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39925\n",
      "I1209 16:22:04.026263 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39925\n",
      "INFO:tensorflow:loss = 0.18339022, step = 800 (18.521 sec)\n",
      "I1209 16:22:04.027511 140132392327040 basic_session_run_hooks.py:260] loss = 0.18339022, step = 800 (18.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40325\n",
      "I1209 16:22:22.533526 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40325\n",
      "INFO:tensorflow:loss = 1.4627669, step = 900 (18.508 sec)\n",
      "I1209 16:22:22.536014 140132392327040 basic_session_run_hooks.py:260] loss = 1.4627669, step = 900 (18.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39758\n",
      "I1209 16:22:41.060333 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39758\n",
      "INFO:tensorflow:loss = 0.26885545, step = 1000 (18.526 sec)\n",
      "I1209 16:22:41.061554 140132392327040 basic_session_run_hooks.py:260] loss = 0.26885545, step = 1000 (18.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40717\n",
      "I1209 16:22:59.554334 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40717\n",
      "INFO:tensorflow:loss = 1.7422236, step = 1100 (18.494 sec)\n",
      "I1209 16:22:59.555423 140132392327040 basic_session_run_hooks.py:260] loss = 1.7422236, step = 1100 (18.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39905\n",
      "I1209 16:23:18.076159 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39905\n",
      "INFO:tensorflow:loss = 1.2785422, step = 1200 (18.522 sec)\n",
      "I1209 16:23:18.077187 140132392327040 basic_session_run_hooks.py:260] loss = 1.2785422, step = 1200 (18.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39297\n",
      "I1209 16:23:36.618769 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39297\n",
      "INFO:tensorflow:loss = 1.1860747, step = 1300 (18.543 sec)\n",
      "I1209 16:23:36.619811 140132392327040 basic_session_run_hooks.py:260] loss = 1.1860747, step = 1300 (18.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.3795\n",
      "I1209 16:23:55.207875 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.3795\n",
      "INFO:tensorflow:loss = 0.3696749, step = 1400 (18.589 sec)\n",
      "I1209 16:23:55.209080 140132392327040 basic_session_run_hooks.py:260] loss = 0.3696749, step = 1400 (18.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39133\n",
      "I1209 16:24:13.756283 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39133\n",
      "INFO:tensorflow:loss = 1.250244, step = 1500 (18.548 sec)\n",
      "I1209 16:24:13.757322 140132392327040 basic_session_run_hooks.py:260] loss = 1.250244, step = 1500 (18.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40575\n",
      "I1209 16:24:32.255004 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40575\n",
      "INFO:tensorflow:loss = 0.4197723, step = 1600 (18.500 sec)\n",
      "I1209 16:24:32.257218 140132392327040 basic_session_run_hooks.py:260] loss = 0.4197723, step = 1600 (18.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39838\n",
      "I1209 16:24:50.779067 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.39838\n",
      "INFO:tensorflow:loss = 0.29437158, step = 1700 (18.523 sec)\n",
      "I1209 16:24:50.780483 140132392327040 basic_session_run_hooks.py:260] loss = 0.29437158, step = 1700 (18.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40325\n",
      "I1209 16:25:09.286540 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40325\n",
      "INFO:tensorflow:loss = 1.3000703, step = 1800 (18.507 sec)\n",
      "I1209 16:25:09.287694 140132392327040 basic_session_run_hooks.py:260] loss = 1.3000703, step = 1800 (18.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42176\n",
      "I1209 16:25:27.730659 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42176\n",
      "INFO:tensorflow:loss = 0.46626627, step = 1900 (18.444 sec)\n",
      "I1209 16:25:27.731790 140132392327040 basic_session_run_hooks.py:260] loss = 0.46626627, step = 1900 (18.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42141\n",
      "I1209 16:25:46.175993 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42141\n",
      "INFO:tensorflow:loss = 1.4548186, step = 2000 (18.445 sec)\n",
      "I1209 16:25:46.176903 140132392327040 basic_session_run_hooks.py:260] loss = 1.4548186, step = 2000 (18.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41681\n",
      "I1209 16:26:04.637092 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41681\n",
      "INFO:tensorflow:loss = 0.36231393, step = 2100 (18.461 sec)\n",
      "I1209 16:26:04.638100 140132392327040 basic_session_run_hooks.py:260] loss = 0.36231393, step = 2100 (18.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40323\n",
      "I1209 16:26:23.144531 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40323\n",
      "INFO:tensorflow:loss = 0.912861, step = 2200 (18.508 sec)\n",
      "I1209 16:26:23.145817 140132392327040 basic_session_run_hooks.py:260] loss = 0.912861, step = 2200 (18.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40529\n",
      "I1209 16:26:41.644916 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.40529\n",
      "INFO:tensorflow:loss = 0.7372533, step = 2300 (18.501 sec)\n",
      "I1209 16:26:41.646804 140132392327040 basic_session_run_hooks.py:260] loss = 0.7372533, step = 2300 (18.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41194\n",
      "I1209 16:27:00.122619 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41194\n",
      "INFO:tensorflow:loss = 0.4778047, step = 2400 (18.477 sec)\n",
      "I1209 16:27:00.123747 140132392327040 basic_session_run_hooks.py:260] loss = 0.4778047, step = 2400 (18.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41408\n",
      "I1209 16:27:18.592921 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41408\n",
      "INFO:tensorflow:loss = 1.4415815, step = 2500 (18.470 sec)\n",
      "I1209 16:27:18.593959 140132392327040 basic_session_run_hooks.py:260] loss = 1.4415815, step = 2500 (18.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41057\n",
      "I1209 16:27:37.075345 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41057\n",
      "INFO:tensorflow:loss = 0.25409546, step = 2600 (18.483 sec)\n",
      "I1209 16:27:37.076764 140132392327040 basic_session_run_hooks.py:260] loss = 0.25409546, step = 2600 (18.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41776\n",
      "I1209 16:27:55.533189 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41776\n",
      "INFO:tensorflow:loss = 0.65149456, step = 2700 (18.458 sec)\n",
      "I1209 16:27:55.534398 140132392327040 basic_session_run_hooks.py:260] loss = 0.65149456, step = 2700 (18.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42456\n",
      "I1209 16:28:13.967750 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42456\n",
      "INFO:tensorflow:loss = 1.9872915, step = 2800 (18.434 sec)\n",
      "I1209 16:28:13.968878 140132392327040 basic_session_run_hooks.py:260] loss = 1.9872915, step = 2800 (18.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.41533\n",
      "I1209 16:28:32.433874 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.41533\n",
      "INFO:tensorflow:loss = 0.8949548, step = 2900 (18.466 sec)\n",
      "I1209 16:28:32.435240 140132392327040 basic_session_run_hooks.py:260] loss = 0.8949548, step = 2900 (18.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43893\n",
      "I1209 16:28:50.819837 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43893\n",
      "INFO:tensorflow:loss = 0.8698113, step = 3000 (18.386 sec)\n",
      "I1209 16:28:50.821369 140132392327040 basic_session_run_hooks.py:260] loss = 0.8698113, step = 3000 (18.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4089\n",
      "I1209 16:29:09.307923 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.4089\n",
      "INFO:tensorflow:loss = 0.74854547, step = 3100 (18.488 sec)\n",
      "I1209 16:29:09.309216 140132392327040 basic_session_run_hooks.py:260] loss = 0.74854547, step = 3100 (18.488 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3164 into training2/model.ckpt.\n",
      "I1209 16:29:20.914755 140132392327040 basic_session_run_hooks.py:606] Saving checkpoints for 3164 into training2/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I1209 16:29:25.934256 140132392327040 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:25.972587 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:29.971791 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:29.988797 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1209 16:29:29.989145 140132392327040 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:30.742271 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:31.102432 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:31.122884 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W1209 16:29:35.227794 140132392327040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:29:35.341480 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1209 16:29:36.106617 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1209 16:29:36.351986 140132392327040 deprecation.py:323] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "W1209 16:29:36.520502 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "W1209 16:29:36.618236 140132392327040 module_wrapper.py:139] From /content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I1209 16:29:37.235950 140132392327040 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-09T16:29:37Z\n",
      "I1209 16:29:37.258881 140132392327040 evaluation.py:255] Starting evaluation at 2019-12-09T16:29:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I1209 16:29:38.476998 140132392327040 monitored_session.py:240] Graph was finalized.\n",
      "2019-12-09 16:29:38.478403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:29:38.479211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-09 16:29:38.479308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-09 16:29:38.479340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-09 16:29:38.479368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2019-12-09 16:29:38.479393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2019-12-09 16:29:38.479433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-12-09 16:29:38.479459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-12-09 16:29:38.479485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-09 16:29:38.479562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:29:38.480189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:29:38.480766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2019-12-09 16:29:38.480815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-09 16:29:38.480830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2019-12-09 16:29:38.480838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2019-12-09 16:29:38.480932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:29:38.481529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:29:38.482105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "INFO:tensorflow:Restoring parameters from training2/model.ckpt-3164\n",
      "I1209 16:29:38.484185 140132392327040 saver.py:1284] Restoring parameters from training2/model.ckpt-3164\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1209 16:29:40.932364 140132392327040 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1209 16:29:41.304158 140132392327040 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 63 images.\n",
      "I1209 16:29:56.593693 140130052470528 coco_evaluation.py:205] Performing evaluation on 63 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1209 16:29:56.594961 140130052470528 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I1209 16:29:56.603437 140130052470528 coco_tools.py:137] DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.87s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.467\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-09-16:29:58\n",
      "I1209 16:29:58.032829 140132392327040 evaluation.py:275] Finished evaluation at 2019-12-09-16:29:58\n",
      "INFO:tensorflow:Saving dict for global step 3164: DetectionBoxes_Precision/mAP = 0.1596833, DetectionBoxes_Precision/mAP (large) = 0.23660475, DetectionBoxes_Precision/mAP (medium) = 0.099237695, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.4670457, DetectionBoxes_Precision/mAP@.75IOU = 0.04484581, DetectionBoxes_Recall/AR@1 = 0.18294252, DetectionBoxes_Recall/AR@10 = 0.35104603, DetectionBoxes_Recall/AR@100 = 0.36418897, DetectionBoxes_Recall/AR@100 (large) = 0.42281047, DetectionBoxes_Recall/AR@100 (medium) = 0.2846199, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.112069435, Loss/BoxClassifierLoss/localization_loss = 0.11159938, Loss/RPNLoss/localization_loss = 0.06786121, Loss/RPNLoss/objectness_loss = 0.15976582, Loss/total_loss = 0.4512958, global_step = 3164, learning_rate = 0.0003, loss = 0.4512958\n",
      "I1209 16:29:58.033250 140132392327040 estimator.py:2049] Saving dict for global step 3164: DetectionBoxes_Precision/mAP = 0.1596833, DetectionBoxes_Precision/mAP (large) = 0.23660475, DetectionBoxes_Precision/mAP (medium) = 0.099237695, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.4670457, DetectionBoxes_Precision/mAP@.75IOU = 0.04484581, DetectionBoxes_Recall/AR@1 = 0.18294252, DetectionBoxes_Recall/AR@10 = 0.35104603, DetectionBoxes_Recall/AR@100 = 0.36418897, DetectionBoxes_Recall/AR@100 (large) = 0.42281047, DetectionBoxes_Recall/AR@100 (medium) = 0.2846199, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.112069435, Loss/BoxClassifierLoss/localization_loss = 0.11159938, Loss/RPNLoss/localization_loss = 0.06786121, Loss/RPNLoss/objectness_loss = 0.15976582, Loss/total_loss = 0.4512958, global_step = 3164, learning_rate = 0.0003, loss = 0.4512958\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3164: training2/model.ckpt-3164\n",
      "I1209 16:30:00.172698 140132392327040 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3164: training2/model.ckpt-3164\n",
      "INFO:tensorflow:global_step/sec: 1.73453\n",
      "I1209 16:30:06.960484 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 1.73453\n",
      "INFO:tensorflow:loss = 0.64155567, step = 3200 (57.652 sec)\n",
      "I1209 16:30:06.961539 140132392327040 basic_session_run_hooks.py:260] loss = 0.64155567, step = 3200 (57.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4404\n",
      "I1209 16:30:25.341489 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.4404\n",
      "INFO:tensorflow:loss = 0.7555851, step = 3300 (18.381 sec)\n",
      "I1209 16:30:25.342583 140132392327040 basic_session_run_hooks.py:260] loss = 0.7555851, step = 3300 (18.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42864\n",
      "I1209 16:30:43.762302 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42864\n",
      "INFO:tensorflow:loss = 1.2520193, step = 3400 (18.421 sec)\n",
      "I1209 16:30:43.763230 140132392327040 basic_session_run_hooks.py:260] loss = 1.2520193, step = 3400 (18.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43373\n",
      "I1209 16:31:02.165920 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43373\n",
      "INFO:tensorflow:loss = 0.7479397, step = 3500 (18.405 sec)\n",
      "I1209 16:31:02.167847 140132392327040 basic_session_run_hooks.py:260] loss = 0.7479397, step = 3500 (18.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4354\n",
      "I1209 16:31:20.563825 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.4354\n",
      "INFO:tensorflow:loss = 1.3527583, step = 3600 (18.397 sec)\n",
      "I1209 16:31:20.564797 140132392327040 basic_session_run_hooks.py:260] loss = 1.3527583, step = 3600 (18.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43475\n",
      "I1209 16:31:38.963938 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43475\n",
      "INFO:tensorflow:loss = 0.7669113, step = 3700 (18.400 sec)\n",
      "I1209 16:31:38.964994 140132392327040 basic_session_run_hooks.py:260] loss = 0.7669113, step = 3700 (18.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.415\n",
      "I1209 16:31:57.431174 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.415\n",
      "INFO:tensorflow:loss = 0.44982183, step = 3800 (18.467 sec)\n",
      "I1209 16:31:57.432412 140132392327040 basic_session_run_hooks.py:260] loss = 0.44982183, step = 3800 (18.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42933\n",
      "I1209 16:32:15.849634 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42933\n",
      "INFO:tensorflow:loss = 0.36259195, step = 3900 (18.419 sec)\n",
      "I1209 16:32:15.850980 140132392327040 basic_session_run_hooks.py:260] loss = 0.36259195, step = 3900 (18.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43886\n",
      "I1209 16:32:34.235903 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43886\n",
      "INFO:tensorflow:loss = 0.36070687, step = 4000 (18.386 sec)\n",
      "I1209 16:32:34.237044 140132392327040 basic_session_run_hooks.py:260] loss = 0.36070687, step = 4000 (18.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43671\n",
      "I1209 16:32:52.629288 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43671\n",
      "INFO:tensorflow:loss = 0.8968697, step = 4100 (18.393 sec)\n",
      "I1209 16:32:52.630427 140132392327040 basic_session_run_hooks.py:260] loss = 0.8968697, step = 4100 (18.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43862\n",
      "I1209 16:33:11.016311 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43862\n",
      "INFO:tensorflow:loss = 0.3401718, step = 4200 (18.388 sec)\n",
      "I1209 16:33:11.017954 140132392327040 basic_session_run_hooks.py:260] loss = 0.3401718, step = 4200 (18.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44119\n",
      "I1209 16:33:29.394675 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44119\n",
      "INFO:tensorflow:loss = 0.1298896, step = 4300 (18.378 sec)\n",
      "I1209 16:33:29.395846 140132392327040 basic_session_run_hooks.py:260] loss = 0.1298896, step = 4300 (18.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44166\n",
      "I1209 16:33:47.771365 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44166\n",
      "INFO:tensorflow:loss = 0.602693, step = 4400 (18.377 sec)\n",
      "I1209 16:33:47.772345 140132392327040 basic_session_run_hooks.py:260] loss = 0.602693, step = 4400 (18.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.42981\n",
      "I1209 16:34:06.188299 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.42981\n",
      "INFO:tensorflow:loss = 0.5142068, step = 4500 (18.417 sec)\n",
      "I1209 16:34:06.189296 140132392327040 basic_session_run_hooks.py:260] loss = 0.5142068, step = 4500 (18.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44668\n",
      "I1209 16:34:24.548164 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44668\n",
      "INFO:tensorflow:loss = 0.15416867, step = 4600 (18.360 sec)\n",
      "I1209 16:34:24.549233 140132392327040 basic_session_run_hooks.py:260] loss = 0.15416867, step = 4600 (18.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45201\n",
      "I1209 16:34:42.889907 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.45201\n",
      "INFO:tensorflow:loss = 0.37502262, step = 4700 (18.342 sec)\n",
      "I1209 16:34:42.890858 140132392327040 basic_session_run_hooks.py:260] loss = 0.37502262, step = 4700 (18.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45253\n",
      "I1209 16:35:01.230013 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.45253\n",
      "INFO:tensorflow:loss = 0.7254775, step = 4800 (18.340 sec)\n",
      "I1209 16:35:01.231112 140132392327040 basic_session_run_hooks.py:260] loss = 0.7254775, step = 4800 (18.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44682\n",
      "I1209 16:35:19.589400 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44682\n",
      "INFO:tensorflow:loss = 0.8453929, step = 4900 (18.360 sec)\n",
      "I1209 16:35:19.591051 140132392327040 basic_session_run_hooks.py:260] loss = 0.8453929, step = 4900 (18.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44453\n",
      "I1209 16:35:37.956491 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44453\n",
      "INFO:tensorflow:loss = 0.242619, step = 5000 (18.366 sec)\n",
      "I1209 16:35:37.957508 140132392327040 basic_session_run_hooks.py:260] loss = 0.242619, step = 5000 (18.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44818\n",
      "I1209 16:35:56.311226 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44818\n",
      "INFO:tensorflow:loss = 0.47743773, step = 5100 (18.355 sec)\n",
      "I1209 16:35:56.312097 140132392327040 basic_session_run_hooks.py:260] loss = 0.47743773, step = 5100 (18.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44689\n",
      "I1209 16:36:14.670270 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44689\n",
      "INFO:tensorflow:loss = 0.5081775, step = 5200 (18.359 sec)\n",
      "I1209 16:36:14.671346 140132392327040 basic_session_run_hooks.py:260] loss = 0.5081775, step = 5200 (18.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44532\n",
      "I1209 16:36:33.034699 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44532\n",
      "INFO:tensorflow:loss = 0.58810455, step = 5300 (18.364 sec)\n",
      "I1209 16:36:33.035712 140132392327040 basic_session_run_hooks.py:260] loss = 0.58810455, step = 5300 (18.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44802\n",
      "I1209 16:36:51.389943 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44802\n",
      "INFO:tensorflow:loss = 0.24224262, step = 5400 (18.355 sec)\n",
      "I1209 16:36:51.390912 140132392327040 basic_session_run_hooks.py:260] loss = 0.24224262, step = 5400 (18.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43931\n",
      "I1209 16:37:09.774637 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43931\n",
      "INFO:tensorflow:loss = 0.5553354, step = 5500 (18.385 sec)\n",
      "I1209 16:37:09.775852 140132392327040 basic_session_run_hooks.py:260] loss = 0.5553354, step = 5500 (18.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44905\n",
      "I1209 16:37:28.126461 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44905\n",
      "INFO:tensorflow:loss = 0.109977335, step = 5600 (18.352 sec)\n",
      "I1209 16:37:28.127954 140132392327040 basic_session_run_hooks.py:260] loss = 0.109977335, step = 5600 (18.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.43379\n",
      "I1209 16:37:46.529787 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.43379\n",
      "INFO:tensorflow:loss = 0.6832558, step = 5700 (18.403 sec)\n",
      "I1209 16:37:46.530856 140132392327040 basic_session_run_hooks.py:260] loss = 0.6832558, step = 5700 (18.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45014\n",
      "I1209 16:38:04.878015 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.45014\n",
      "INFO:tensorflow:loss = 0.26328698, step = 5800 (18.348 sec)\n",
      "I1209 16:38:04.879244 140132392327040 basic_session_run_hooks.py:260] loss = 0.26328698, step = 5800 (18.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4564\n",
      "I1209 16:38:23.205099 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.4564\n",
      "INFO:tensorflow:loss = 0.37441432, step = 5900 (18.327 sec)\n",
      "I1209 16:38:23.206199 140132392327040 basic_session_run_hooks.py:260] loss = 0.37441432, step = 5900 (18.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.431\n",
      "I1209 16:38:41.617910 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.431\n",
      "INFO:tensorflow:loss = 0.16837372, step = 6000 (18.413 sec)\n",
      "I1209 16:38:41.619048 140132392327040 basic_session_run_hooks.py:260] loss = 0.16837372, step = 6000 (18.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.45729\n",
      "I1209 16:38:59.941988 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.45729\n",
      "INFO:tensorflow:loss = 0.34431976, step = 6100 (18.324 sec)\n",
      "I1209 16:38:59.942938 140132392327040 basic_session_run_hooks.py:260] loss = 0.34431976, step = 6100 (18.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.44338\n",
      "I1209 16:39:18.312929 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 5.44338\n",
      "INFO:tensorflow:loss = 0.29254362, step = 6200 (18.371 sec)\n",
      "I1209 16:39:18.313855 140132392327040 basic_session_run_hooks.py:260] loss = 0.29254362, step = 6200 (18.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6216 into training2/model.ckpt.\n",
      "I1209 16:39:21.087383 140132392327040 basic_session_run_hooks.py:606] Saving checkpoints for 6216 into training2/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I1209 16:39:25.885512 140132392327040 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:25.918744 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:29.644261 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:29.663727 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1209 16:39:29.664268 140132392327040 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:30.446318 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:30.814539 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:30.833445 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1209 16:39:35.635227 140132392327040 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I1209 16:39:37.542140 140132392327040 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-09T16:39:37Z\n",
      "I1209 16:39:37.562404 140132392327040 evaluation.py:255] Starting evaluation at 2019-12-09T16:39:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I1209 16:39:38.468396 140132392327040 monitored_session.py:240] Graph was finalized.\n",
      "2019-12-09 16:39:38.469241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:39:38.469869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-12-09 16:39:38.470004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2019-12-09 16:39:38.470069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2019-12-09 16:39:38.470136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2019-12-09 16:39:38.470221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2019-12-09 16:39:38.470265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2019-12-09 16:39:38.470302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2019-12-09 16:39:38.470352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-12-09 16:39:38.470443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:39:38.470958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:39:38.471457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2019-12-09 16:39:38.471516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-12-09 16:39:38.471535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2019-12-09 16:39:38.471548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2019-12-09 16:39:38.471647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:39:38.472165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-12-09 16:39:38.472615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "INFO:tensorflow:Restoring parameters from training2/model.ckpt-6216\n",
      "I1209 16:39:38.474925 140132392327040 saver.py:1284] Restoring parameters from training2/model.ckpt-6216\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1209 16:39:40.974613 140132392327040 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1209 16:39:41.309000 140132392327040 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 63 images.\n",
      "I1209 16:39:55.820443 140128456849152 coco_evaluation.py:205] Performing evaluation on 63 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1209 16:39:55.821333 140128456849152 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I1209 16:39:55.825562 140128456849152 coco_tools.py:137] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.606\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-09-16:39:57\n",
      "I1209 16:39:57.118554 140132392327040 evaluation.py:275] Finished evaluation at 2019-12-09-16:39:57\n",
      "INFO:tensorflow:Saving dict for global step 6216: DetectionBoxes_Precision/mAP = 0.21868598, DetectionBoxes_Precision/mAP (large) = 0.28493372, DetectionBoxes_Precision/mAP (medium) = 0.19351697, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6056602, DetectionBoxes_Precision/mAP@.75IOU = 0.090076745, DetectionBoxes_Recall/AR@1 = 0.25826755, DetectionBoxes_Recall/AR@10 = 0.3946177, DetectionBoxes_Recall/AR@100 = 0.41276377, DetectionBoxes_Recall/AR@100 (large) = 0.44239652, DetectionBoxes_Recall/AR@100 (medium) = 0.38789475, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13615015, Loss/BoxClassifierLoss/localization_loss = 0.13030098, Loss/RPNLoss/localization_loss = 0.06910201, Loss/RPNLoss/objectness_loss = 0.15661265, Loss/total_loss = 0.49216586, global_step = 6216, learning_rate = 0.0003, loss = 0.49216586\n",
      "I1209 16:39:57.118931 140132392327040 estimator.py:2049] Saving dict for global step 6216: DetectionBoxes_Precision/mAP = 0.21868598, DetectionBoxes_Precision/mAP (large) = 0.28493372, DetectionBoxes_Precision/mAP (medium) = 0.19351697, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6056602, DetectionBoxes_Precision/mAP@.75IOU = 0.090076745, DetectionBoxes_Recall/AR@1 = 0.25826755, DetectionBoxes_Recall/AR@10 = 0.3946177, DetectionBoxes_Recall/AR@100 = 0.41276377, DetectionBoxes_Recall/AR@100 (large) = 0.44239652, DetectionBoxes_Recall/AR@100 (medium) = 0.38789475, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.13615015, Loss/BoxClassifierLoss/localization_loss = 0.13030098, Loss/RPNLoss/localization_loss = 0.06910201, Loss/RPNLoss/objectness_loss = 0.15661265, Loss/total_loss = 0.49216586, global_step = 6216, learning_rate = 0.0003, loss = 0.49216586\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6216: training2/model.ckpt-6216\n",
      "I1209 16:39:57.137115 140132392327040 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6216: training2/model.ckpt-6216\n",
      "INFO:tensorflow:global_step/sec: 1.83632\n",
      "I1209 16:40:12.769795 140132392327040 basic_session_run_hooks.py:692] global_step/sec: 1.83632\n",
      "INFO:tensorflow:loss = 0.28472197, step = 6300 (54.458 sec)\n",
      "I1209 16:40:12.771599 140132392327040 basic_session_run_hooks.py:260] loss = 0.28472197, step = 6300 (54.458 sec)\n",
      "Traceback (most recent call last):\n",
      "  File \"model_main.py\", line 109, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"model_main.py\", line 105, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "CPU times: user 4.87 s, sys: 581 ms, total: 5.45 s\n",
      "Wall time: 22min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python model_main.py --logtostderr --model_dir=training2/ --pipeline_config_path=training2/pipeline2.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGyz7CfPgT7D"
   },
   "source": [
    "#### Generate Inference Graph\n",
    "Replace the path to `model.ckpt-XXXX` with the highest checkpoint number. Ignore the `.data-00000-of-00001` from the input.)\n",
    "\n",
    "This code will create a new folder called `inference_graph` containing `frozen_inference_graph` based on the selected model that will be used to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zPMHNup0fw2c",
    "outputId": "4b2b4852-4d42-43c0-b941-9fd2c1aabff7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training2/pipeline2.config --trained_checkpoint_prefix training2/model.ckpt-6216 --output_directory inference_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bic3W3KMjeVh"
   },
   "source": [
    "### Object Detection\n",
    "Current working directory should be located in `/content/gdrive/My Drive/SUTD/cds_nude_censoring/models/research/object_detection`  \n",
    "\n",
    "The object detection uses tensorflow 2.0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Documents\\cds_nude_censoring\\models\\research\\object_detection\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\andre\\\\Documents\\\\cds_nude_censoring\\\\models\\\\research\\\\object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39suDnpJhgXS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQBpHR8jlIXL"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = 'inference_graph'\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_DIR + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = 'training2/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jk5LoZiKmhTO"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.compat.v1.GraphDef()\n",
    "  with tf.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji1qN9OamIoe"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqaxFDx5mQ0E"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "    image_tensor = tf.compat.v1.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "                            feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "        'detection_classes'][0].astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaekz1fDpSA1"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "Xi9lwbFdn13K",
    "outputId": "50472f0f-2027-45e0-de73-df73143d5e7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../images/train_set\\0030.jpg\n",
      "Image saved as ./test_1.jpeg, time taken:  59.411181926727295 s\n",
      "../../../images/train_set\\0033.jpg\n",
      "Image saved as ./test_2.jpeg, time taken:  32.504643201828 s\n",
      "../../../images/train_set\\0046.jpg\n",
      "Image saved as ./test_3.jpeg, time taken:  34.250489950180054 s\n",
      "../../../images/train_set\\0062.jpg\n",
      "Image saved as ./test_4.jpeg, time taken:  29.803219079971313 s\n",
      "../../../images/train_set\\007-1.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bb29769881aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../../predicted images/val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image saved as ./test_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpeg, time taken: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1905\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1907\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1709\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 619\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    879\u001b[0m         return self._make_image(\n\u001b[0;32m    880\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m             unsampled=unsampled)\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    510\u001b[0m                     \u001b[0m_interpd_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_interpolation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                     self.get_filternorm(), self.get_filterrad())\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;31m#recombine rgb and alpha channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CONTENT_PATH = '../../../../../../../*.jpg'\n",
    "CDS_NUDE_CENSORING_IMAGE_PATH = '../../../images/train_set/*.jpg'\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        ops = tf.compat.v1.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "          ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.compat.v1.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "        counter = 1\n",
    "        for image_path in glob.glob(CDS_NUDE_CENSORING_IMAGE_PATH):\n",
    "            t1 = time.time()\n",
    "\n",
    "            print(image_path)\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            # Actual detection.\n",
    "            output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                output_dict['detection_boxes'],\n",
    "                output_dict['detection_classes'],\n",
    "                output_dict['detection_scores'],\n",
    "                category_index,\n",
    "                instance_masks=output_dict.get('detection_masks'),\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=4)\n",
    "            plt.figure(figsize=(400, 300))\n",
    "            plt.imshow(image_np)\n",
    "            plt.savefig('../../../predicted images/val_' + str(counter) + '.jpeg', format='jpeg')\n",
    "            print('Image saved as ./test_' + str(counter) + '.jpeg, time taken: ', time.time() - t1, 's')\n",
    "            counter += 1\n",
    "        sess.close()\n",
    "        print('Completed...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in Camera Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yMlWIv9hmUfe",
    "outputId": "dec21774-b685-4d93-c1be-98f389f20bb1"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-83dcaf8e7da7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[0mimage_np_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[1;31m# Actual detection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_inference_for_single_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                         \u001b[1;31m# Visualization of the results of a detection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         vis_util.visualize_boxes_and_labels_on_image_array(\n",
      "\u001b[1;32m<ipython-input-44-5956a5b41386>\u001b[0m in \u001b[0;36mrun_inference_for_single_image\u001b[1;34m(image, graph)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Run inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     output_dict = sess.run(tensor_dict,\n\u001b[1;32m---> 21\u001b[1;33m                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# all outputs are float32 numpy arrays, so convert types as appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "                # Get handles to input and output tensors\n",
    "                ops = tf.compat.v1.get_default_graph().get_operations()\n",
    "                all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "                tensor_dict = {}\n",
    "                for key in [\n",
    "                  'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                  'detection_classes', 'detection_masks'\n",
    "                ]:\n",
    "                    tensor_name = key + ':0'\n",
    "                    if tensor_name in all_tensor_names:\n",
    "                        tensor_dict[key] = tf.compat.v1.get_default_graph().get_tensor_by_name(tensor_name)\n",
    "                count = 0\n",
    "                while True:\n",
    "                    if count % 8 == 0:\n",
    "                        ret, image_np = cap.read()\n",
    "                        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                        # Actual detection.\n",
    "                        output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "                        # Visualization of the results of a detection.\n",
    "                        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                            image_np,\n",
    "                            output_dict['detection_boxes'],\n",
    "                            output_dict['detection_classes'],\n",
    "                            output_dict['detection_scores'],\n",
    "                            category_index,\n",
    "                            instance_masks=output_dict.get('detection_masks'),\n",
    "                            use_normalized_coordinates=True,\n",
    "                            line_thickness=4)\n",
    "                        cv2.imshow('object_detection', cv2.resize(image_np, (800, 600)))\n",
    "                        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                            cap.release()\n",
    "                            cv2.destroyAllWindows()\n",
    "                            break\n",
    "                    count+=1\n",
    "except Exception as e:\n",
    "    sess.close()\n",
    "    print(e)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "generate_tfrecord.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
