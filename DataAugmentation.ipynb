{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "classification = {\n",
    "    0: \"nsfw\",\n",
    "    1: \"sfw\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "img_width , img_height = 255,255\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape = (3, img_width, img_height)\n",
    "else:\n",
    "    shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "predict_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6266 images belonging to 2 classes.\n",
      "Found 1302 images belonging to 2 classes.\n",
      "Found 13 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = './dataset/train_set'\n",
    "validation_data_dir = './dataset/validation_set'\n",
    "predict_data_dir = './dataset/predict_set'\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "prediction_generator = predict_datagen.flow_from_directory(\n",
    "    predict_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    shuffle=False,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 0.6929 - accuracy: 0.5112 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "195/195 [==============================] - 43s 222ms/step - loss: 0.6928 - accuracy: 0.5133 - val_loss: 0.6997 - val_accuracy: 0.4969\n",
      "Epoch 3/25\n",
      "195/195 [==============================] - 44s 226ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6876 - val_accuracy: 0.4969\n",
      "Epoch 4/25\n",
      "195/195 [==============================] - 43s 218ms/step - loss: 0.6930 - accuracy: 0.5093 - val_loss: 0.6934 - val_accuracy: 0.5142\n",
      "Epoch 5/25\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 0.6927 - accuracy: 0.5160 - val_loss: 0.6919 - val_accuracy: 0.4843\n",
      "Epoch 6/25\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 0.6930 - accuracy: 0.5106 - val_loss: 0.6979 - val_accuracy: 0.5047\n",
      "Epoch 7/25\n",
      "195/195 [==============================] - 38s 195ms/step - loss: 0.6927 - accuracy: 0.5135 - val_loss: 0.6981 - val_accuracy: 0.5000\n",
      "Epoch 8/25\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 0.6929 - accuracy: 0.5098 - val_loss: 0.6949 - val_accuracy: 0.5031\n",
      "Epoch 9/25\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 0.6928 - accuracy: 0.5114 - val_loss: 0.6934 - val_accuracy: 0.5016\n",
      "Epoch 10/25\n",
      "195/195 [==============================] - 37s 192ms/step - loss: 0.6927 - accuracy: 0.5135 - val_loss: 0.6839 - val_accuracy: 0.4976\n",
      "Epoch 11/25\n",
      "195/195 [==============================] - 37s 188ms/step - loss: 0.6930 - accuracy: 0.5093 - val_loss: 0.6904 - val_accuracy: 0.5071\n",
      "Epoch 12/25\n",
      "195/195 [==============================] - 39s 197ms/step - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6949 - val_accuracy: 0.4945\n",
      "Epoch 13/25\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 0.6929 - accuracy: 0.5106 - val_loss: 0.6891 - val_accuracy: 0.5063\n",
      "Epoch 14/25\n",
      "195/195 [==============================] - 36s 184ms/step - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6934 - val_accuracy: 0.5039\n",
      "Epoch 15/25\n",
      "195/195 [==============================] - 35s 180ms/step - loss: 0.6930 - accuracy: 0.5109 - val_loss: 0.6920 - val_accuracy: 0.4858\n",
      "Epoch 16/25\n",
      "195/195 [==============================] - 35s 179ms/step - loss: 0.6927 - accuracy: 0.5130 - val_loss: 0.6964 - val_accuracy: 0.5055\n",
      "Epoch 17/25\n",
      "195/195 [==============================] - 35s 178ms/step - loss: 0.6928 - accuracy: 0.5119 - val_loss: 0.6981 - val_accuracy: 0.4882\n",
      "Epoch 18/25\n",
      "195/195 [==============================] - 35s 180ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6902 - val_accuracy: 0.5165\n",
      "Epoch 19/25\n",
      "195/195 [==============================] - 35s 178ms/step - loss: 0.6928 - accuracy: 0.5119 - val_loss: 0.6861 - val_accuracy: 0.4929\n",
      "Epoch 20/25\n",
      "195/195 [==============================] - 35s 178ms/step - loss: 0.6927 - accuracy: 0.5130 - val_loss: 0.6978 - val_accuracy: 0.4945\n",
      "Epoch 21/25\n",
      "195/195 [==============================] - 35s 179ms/step - loss: 0.6927 - accuracy: 0.5141 - val_loss: 0.6935 - val_accuracy: 0.5055\n",
      "Epoch 22/25\n",
      "195/195 [==============================] - 35s 182ms/step - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6971 - val_accuracy: 0.5031\n",
      "Epoch 23/25\n",
      "195/195 [==============================] - 35s 178ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6906 - val_accuracy: 0.4937\n",
      "Epoch 24/25\n",
      "195/195 [==============================] - 35s 180ms/step - loss: 0.6927 - accuracy: 0.5138 - val_loss: 0.6862 - val_accuracy: 0.5047\n",
      "Epoch 25/25\n",
      "195/195 [==============================] - 35s 178ms/step - loss: 0.6929 - accuracy: 0.5088 - val_loss: 0.6920 - val_accuracy: 0.5024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1806a993e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=6266 // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=1302 // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1299 images belonging to 2 classes.\n",
      "loss: 0.6920192837715149 accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = './dataset/test_set'\n",
    "test_it = test_datagen.flow_from_directory(\n",
    "    test_data_dir, \n",
    "    target_size=(img_width, img_height), \n",
    "    class_mode='binary', \n",
    "    batch_size=batch_size\n",
    ")\n",
    "result = model.evaluate_generator(test_it, steps=32)\n",
    "print('loss:', result[0], 'accuracy:', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358],\n",
       "       [0.5109358]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(prediction_generator)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5109358]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(predict_data_dir + '/nsfw/10.jpg')\n",
    "data = img_to_array(img)\n",
    "data = data.reshape((1,) + data.shape)\n",
    "pred = model.predict(data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nsfw': 0, 'sfw': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
